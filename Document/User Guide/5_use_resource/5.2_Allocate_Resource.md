[userguide]: https://github.com/dasandata/Open_HPC/tree/master/Document/User%20Guide#-%EB%AA%A9%EC%B0%A8
[ohpc]: http://openhpc.community/
[slurm]: https://slurm.schedmd.com/

[4]: https://github.com/dasandata/Open_HPC/tree/master/Document/User%20Guide/4_app_env
[4.1]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.1_Anaconda.md
[4.2]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.2_Module.md
[4.3]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.3_Docker.md
[4.4]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.4_Singularity.md

[5]: https://github.com/dasandata/Open_HPC/tree/master/Document/User%20Guide/5_use_resource
[5.1]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/5_use_resource/5.1_Resource_manager_Intro.md
[5.2]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/5_use_resource/5.2_Allocate_Resource.md
[5.3]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/5_use_resource/5.3_Priority_submitted_job_and_start_time.md

## [## 5.2  클러스터 자원 배정(요청)][5]  

**자원 관리자(Resource Manager)** 를 통해 리소스(node 및 GPU)를 배정받고  
[4. 응용프로그램 사용환경 구성 및 시험][4] 에서 시험해 보았던 샘플 코드를  
배정받은 리소스(node 및 GPU) 에서 실행해 보겠습니다.

### [### 5.2.1  srun 을 이용한  Interactive (대화형) 작업][5.2]
```bash
# gpu 1개를 사용할 수 있는 node 요청.
srun  --gres=gpu:1   --pty bash -i

# 할당된 작업의 대기열 (queue)상태 확인.
squeue -u $USER
squeuelong  -u $USER

# 할당 받은 gpu 번호 확인.
echo $CUDA_VISIBLE_DEVICES

# 노드의 gpu 상태 확인.
nvidia-smi
```

Anaconda 의 경우 기존 방법대로 실행할 수 있습니다.

### [### 4.1.3 Anaconda 환경에서 TensorFlow Sample Code 실행.][4.1]

```bash
# 생성된 환경 목록 확인.
conda env list

# 환경 활성화.
conda activate   NEW-py36-tf1.11-cuda9.0  

# Sample Code 를 실행해 보기 전에 gpu 상태 확인
gpustat

nvidia-smi

# Sample Code 실행 1 (short)
python  ~/TensorFlow-Examples/examples/3_NeuralNetworks/neural_network_raw.py
```

***

Docker 의 경우 기존 방법에 `-e NVIDIA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES ` 옵션을 추가해서 실행 해야 합니다.  
이 옵션을 누락할 경우 다른 사용자의 작업이 돌고 있는 GPU 에 중첩해서 작업이 돌아가서  
기존 작업과 새로운 작업이 모두 중단될 가능성이 높습니다.  

### [### 4.3.4 TensorFlow Docker 컨테이너로 파이썬 코드 실행. (--runtime=nvidia 옵션)][4.3]

아래와 같이 실행할 수 있습니다.

```bash
### sample data file 이 download 되는 tmp 폴더도 연결 시킵니다.

mkdir /tmp/$USER
docker run -u $UID:$GROUPS --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES \
   --rm  -v ~:/home/$USER  -v /tmp/$USER:/tmp  \
   tensorflow/tensorflow:1.11.0-gpu-py3  python  ~/TensorFlow-Examples/examples/3_NeuralNetworks/neural_network_raw.py

```





***

## [끝][5.2]
