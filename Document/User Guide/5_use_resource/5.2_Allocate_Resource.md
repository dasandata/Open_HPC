[userguide]: https://github.com/dasandata/Open_HPC/tree/master/Document/User%20Guide#-%EB%AA%A9%EC%B0%A8
[ohpc]: http://openhpc.community/
[slurm]: https://slurm.schedmd.com/

[4]: https://github.com/dasandata/Open_HPC/tree/master/Document/User%20Guide/4_app_env
[4.1]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.1_Anaconda.md
[4.2]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.2_Module.md
[4.3]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.3_Docker.md
[4.4]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/4_app_env/4.4_Singularity.md

[5]: https://github.com/dasandata/Open_HPC/tree/master/Document/User%20Guide/5_use_resource
[5.1]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/5_use_resource/5.1_Resource_manager_Intro.md
[5.2]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/5_use_resource/5.2_Allocate_Resource.md
[5.3]: https://github.com/dasandata/Open_HPC/blob/master/Document/User%20Guide/5_use_resource/5.3_Priority_submitted_job_and_start_time.md

## [## 5.2  클러스터 자원 배정][5]  

**자원 관리자(Resource Manager)** 를 통해 리소스(node 및 GPU)를 배정받고  
[4. 응용프로그램 사용환경 구성 및 시험][4] 에서 시험해 보았던 샘플 코드를  
배정받은 리소스(node 및 GPU) 에서 실행해 보겠습니다.

### [### 5.2.1  srun 을 이용한  Interactive (대화형) 작업][5.2]

srun 을 이용한 Interactive (대화형) 작업은 실시간으로 명령을 입력하과 결과를 확인할 수 있어  
의도했던 작업이 잘 수행 되는지 즉시 확실할 수 있는 장점이 있지만,    
작업이 끝나도 자동으로 종료되지 않으므로 **클러스터 자원이 낭비**되는 요인이 될 수 있습니다.   
<br>
작업 시작시 제한시간을 지정 하거나 가능하다면 디버깅 용도로만 사용는 것을 권장 하며,   
일부 클러스터 시스템 에서는 srun 을 통한 작업의 제한시간이 짧게 적용 되는 경우가 있습니다.    

```bash
cd ~

# 할당된 작업의 대기열 (queue)상태 확인.
echo  $USER   ## 현재 사용자의 id
squeue      -u $USER
squeuelong  -u $USER

# gpu 1개를 사용할 수 있는 리소스(node) 요청, 사용 시간은 1시간으로 지정.
srun  --gres=gpu:1  --time=1:00:00  --pty bash -i

# 리소스를 할당 받은 후 할당된 작업의 대기열 (queue)상태 재 확인.
echo  $USER   ## 현재 사용자의 id
squeue      -u $USER
squeuelong  -u $USER

# 할당 받은 gpu 번호 확인.
echo  $CUDA_VISIBLE_DEVICES

# 노드의 gpu 상태 확인.
gpustat

nvidia-smi
```

#### #### Anaconda 의 경우
**RTX 계열 GPU 의 경우 cuda 11.0** 버젼이 필요 하므로
**cuda 11.0 과 tessorflow 2.4** 가 포함된 환경을 conda 생성해 줍니다.

```bash
cd ~

# conda 환경 생성.
conda deactivate
conda create   -n py38-tf2.4-cuda11.0   -c anaconda  python==3.8.5  cudatoolkit=11.0  

conda activate   py38-tf2.4-cuda11.0
pip install      tensorflow-gpu==2.4  

# Tensorflow 2.4용 샘플파일 다운로드.
wget https://raw.githubusercontent.com/dasandata/Open_HPC/master/Document/User%20Guide/6_etc/dcgan-py38-tf2.4-cuda11.0.py

# Sample Code 를 실행해 보기 전에 gpu 상태 확인
gpustat

nvidia-smi

# Sample Code 실행 1
python  ~/dcgan-py38-tf2.4-cuda11.0.py
```

***

#### #### Module 의 경우
리소스를 배정 받아 계산 노드로 진입한 후에도 login 노드와 동일하게 module 명령을 사용할 수 있습니다.

```bash
ml purge
ml

which nvcc ; echo ; nvcc -V

ml av | grep cuda
ml load cuda/10.0

which nvcc ; echo ; nvcc -V

ml swap   cuda/10.0  cuda/11.0
which nvcc ; echo ; nvcc -V
```

***

#### #### Docker 의 경우  
기존 방법에 `-e NVIDIA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES ` 옵션을 추가해서 실행 해야 합니다.  
SLURM을 통해 할당받은 GPU 번호 - $CUDA_VISIBLE_DEVICES) - 를 Docker 의 컨테이너에게 전달하는 부분이며   
**이 옵션을 누락할 경우 다른 사용자의 작업이 돌고 있는 GPU 에 중첩**해서 작업이 돌아갈 수 있어서   
기존 작업과 새로운 **작업이 모두 중단**될 가능성이 높습니다.  

***

**RTX 계열 GPU 의 경우 cuda 11.0** 버젼이 필요 하므로  
**cuda 11.0 과 tessorflow 2.4** 로 구성된 새로운 Docker image를 내려 받아 진행 합니다.  

```bash
cd ~

# Tensorflow 2.4용 샘플파일 다운로드.
wget https://raw.githubusercontent.com/dasandata/Open_HPC/master/Document/User%20Guide/6_etc/dcgan-py38-tf2.4-cuda11.0.py

# Docker Imaage 다운로드(pull)
docker pull   dasandata/tensorflow:2.4.1-gpu-py3.8-cuda11.0

# 실행.
docker run --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES \
   --rm  -v ~:/home/$USER  \
    dasandata/tensorflow:2.4.1-gpu-py3.8-cuda11.0 \
    python  ~/dcgan-py38-tf2.4-cuda11.0.py

```

***

#### #### singularity 의 경우 #1
앞서 실행한 Docker image를 singularity image 로 build 한 후 사용 합니다.

```bash
cd ~

# Tensorflow 2.4용 샘플파일 다운로드.
wget https://raw.githubusercontent.com/dasandata/Open_HPC/master/Document/User%20Guide/6_etc/dcgan-py38-tf2.4-cuda11.0.py

# singularity Module Load
ml purge
ml load singularity

singularity  build     ~/tf-2.4-gpu-py3.8-cuda11.0.simg   docker://dasandata/tensorflow:2.4.1-gpu-py3.8-cuda11.0

singularity exec --nv  ~/tf-2.4-gpu-py3.8-cuda11.0.simg   python  ~/dcgan-py38-tf2.4-cuda11.0.py

```

#### #### singularity 의 경우 #2 (module을 통해 cuda 사용)

singularity(docker)이미지 내에 cuda가 포함되어 있지 않은 경우    
module 과 singularity 의 bind 옵션을 사용해서 cuda 를 사용할 수 있습니다.   

```bash
cd ~

# singularity Module Load
ml purge
ml load singularity

# 이미지 생성 확인.
singularity  build     ~/tf-2.4-gpu-py3.8-nocuda.simg   docker://dasandata/tensorflow:2.4.1-gpu-py3.8-nocuda

# images 내부에 선언된 $LD_LIBRARY_PATH 확인.
singularity exec --nv  ~/tf-2.4-gpu-py3.8-nocuda.simg     echo $LD_LIBRARY_PATH

# cuda 11.0 Module Load
ml load cuda/11.0

# images 내부에 선언된 $LD_LIBRARY_PATH 변화 확인.
singularity exec --nv  ~/tf-2.4-gpu-py3.8-nocuda.simg     echo $LD_LIBRARY_PATH
singularity exec --nv  ~/tf-2.4-gpu-py3.8-nocuda.simg     ls -l /opt/

### module 을 통해 load 된 cuda를 사용할 수 있도록 /opt/ohpc 를 이미지와 연결(Bind)
singularity exec --nv  -B /opt/ohpc:/opt/ohpc   ~/tf-2.4-gpu-py3.8-nocuda.simg \
    python   ~/dcgan-py38-tf2.4-cuda11.0.py
```

### [### 5.2.2  sbatch 을 이용한  Batch (일괄형) 작업][5.2]

앞서 srun 으로 Interactive (대화형) 작업들을 스크립트(Script) 파일로 만들어서   
sbatch 명령으로 노드에 작업을 제출(submit) 해 보겠습니다.  






***

## [끝][5.2]
